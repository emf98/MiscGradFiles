{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45b368d1-a1f3-4db5-90b2-df877c04748c",
   "metadata": {},
   "source": [
    "So ideally this code will work similarly to the other diagnostic-evaluation codes but now only in reference to SSW-specific scenarios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f1203a1-693f-4593-8657-c1f67a7aad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import scipy.stats\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1490ae6f-2c7f-4e87-b897-db1d7d65c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##N20 related gph and 850 temp files ... will just use this for getting cap values. \n",
    "infile = open(\"../../../New_ERAfiles/N20_gph_NEW.p\", 'rb')\n",
    "gph = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../../../New_ERAfiles/N20_temp850_NEW.p\", 'rb')\n",
    "temp = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../../../New_ERAfiles/N20_temp850_time_NEW.p\", 'rb')\n",
    "temp_time = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../../../New_ERAfiles/N20_gph_time_NEW.p\", 'rb')\n",
    "gph_time = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../../../New_ERAfiles/N20_gph_lat_NEW.p\", 'rb')\n",
    "gph_lat = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../../../New_ERAfiles/N20_gph_lon_NEW.p\", 'rb')\n",
    "gph_lon = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e134a9d-3885-463a-a508-16e08163e427",
   "metadata": {},
   "outputs": [],
   "source": [
    "##N20 cluster labels\n",
    "infile = open(\"../ClusterLabels/NEW_GPHcluster_labels_HOURLY.p\", 'rb') \n",
    "N20label_H = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../ClusterLabels/N20_HOURLY_ANOMcluster_labels.p\", 'rb') \n",
    "NAlabel_H = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9228b9fe-f925-4b9a-8318-853732a4d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "##All lat cluster labels\n",
    "infile = open(\"../ClusterLabels/ALL_HOURLY_GPHcluster_labels.p\", 'rb') \n",
    "ALLlabel_H = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../ClusterLabels/ALL_HOURLY_ANOMcluster_labels.p\", 'rb') \n",
    "AAlabel_H = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd587bd3-4cf5-426b-85ab-30a730032306",
   "metadata": {},
   "outputs": [],
   "source": [
    "##import relevant Elliptical Value Files \n",
    "#old root is ../../Ellipse_ERAI_data/\n",
    "infile = open(\"../../../New_EllipseVals/ephi10_NEW.p\", 'rb')\n",
    "ephi10 = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../../../New_EllipseVals/ephi_ratio10_NEW.p\", 'rb')\n",
    "rat10 = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../../../New_EllipseVals/ephi_size10_NEW.p\", 'rb')\n",
    "size10 = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../../../New_EllipseVals/ephi_cenlat10_NEW.p\", 'rb')\n",
    "cenlat10 = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../../../New_EllipseVals/ephi_cenlon10_NEW.p\", 'rb')\n",
    "cenlon10 = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../../../New_EllipseVals/ephi_wind10_NEW.p\", 'rb')\n",
    "wind10 = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081e48ef-142c-45e5-b851-12388facb9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open(\"../N20_UW_lat.p\", 'rb')\n",
    "unweighted_lat = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../N20_UW_lon.p\", 'rb') \n",
    "unweighted_lon = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc7ec912-aec1-439b-b5e9-4ab943d1a09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(385, 528)\n"
     ]
    }
   ],
   "source": [
    "##need to do something to code in dates for x-axis \n",
    "year = [2000,2001,2002,2003,2005,2006,2007,2008,2009,2012,2017,2018]\n",
    "sswcl = [1,2,3,4,6,7,8,9,10,13,18,19]\n",
    "\n",
    "normal_year = pd.date_range('2000-11-01','2001-04-01', \n",
    "              freq='6H').strftime(\"%m/%d\").tolist()\n",
    "leap_year = pd.date_range('1999-11-01','2000-04-01', \n",
    "              freq='6H').strftime(\"%m/%d\").tolist()\n",
    "\n",
    "dates = [(385,528),(176,319),(256,399),(208,351),(268,411),(404,547),(396,539),(280,423),(344,487),(212,355),(356,499),(192,335)]\n",
    "print(dates[0])\n",
    "\n",
    "ephi10[0,int(dates[0][0]):int(dates[0][1])]\n",
    "xt = leap_year[int(dates[0][0]):int(dates[0][1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61554358-534e-4e83-a0da-6e88f77e8f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c666c45-1cd6-4456-95bc-dd2fa0cfef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##separate out metric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d8cf84f-c924-418c-b5a0-f0e82945f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#non-stacked\n",
    "##creating DataArray for gph\n",
    "gph = xr.DataArray(data= gph, \n",
    "                       dims = [\"time\",\"lat\",\"lon\"],\n",
    "                       coords = dict(\n",
    "                           time = gph_time,\n",
    "                           lat = unweighted_lat,\n",
    "                           lon = unweighted_lon)\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90248698-4194-499b-b428-f07d67444729",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = gph.sel(lat=slice(60,90)).values\n",
    "gp1 = np.nanmean(gp,axis = 1)\n",
    "gp2 = np.nanmean(gp1,axis = 1)\n",
    "gp2.shape\n",
    "\n",
    "gp_f = np.reshape(gp2,(20,608))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6299bcfe-7d5f-4237-9bcd-90eafbc2727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate daily mean values\n",
    "daily_mean_gph = gph.groupby('time.dayofyear').mean()\n",
    "#test gph anomaly\n",
    "daily_anom_gph = gph.groupby('time.dayofyear') - daily_mean_gph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1b70c9a-3c34-4191-81b0-64d89bb4c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = daily_anom_gph.sel(lat=slice(60,90)).values\n",
    "ga1 = np.nanmean(ga,axis = 1)\n",
    "ga2 = np.nanmean(ga1,axis = 1)\n",
    "ga2.shape\n",
    "\n",
    "ga_f = np.reshape(ga2,(20,608))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2200cc5a-a129-4be7-9f45-6ff4ad73a1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#non-stacked\n",
    "##creating DataArray for gph\n",
    "temp = xr.DataArray(data= temp, \n",
    "                       dims = [\"time\",\"lat\",\"lon\"],\n",
    "                       coords = dict(\n",
    "                           time = temp_time,\n",
    "                           lat = unweighted_lat,\n",
    "                           lon = unweighted_lon)\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6090ccb-77d0-429d-a9c9-1578c88bc28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = temp.sel(lat=slice(60,90)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a214d58-eb0e-47e1-a79f-4681cae94b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12160,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm1 = np.nanmean(tm,axis = 1)\n",
    "tm2 = np.nanmean(tm1,axis = 1)\n",
    "tm2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50264022-29e6-4df0-854f-e1f4fb9707b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_f = np.reshape(tm2,(20,608))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a0eabfa-15d9-4e2d-942d-4d1f6f3ea213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate daily mean values\n",
    "daily_mean_temp = temp.groupby('time.dayofyear').mean()\n",
    "#test gph anomaly\n",
    "daily_anom_temp = temp.groupby('time.dayofyear') - daily_mean_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63881447-e03c-4196-9959-66a1ca7d3cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ta = daily_anom_temp.sel(lat=slice(60,90)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "931a30c0-d097-4553-90e3-4e85008ff39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12160,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ta1 = np.nanmean(ta,axis = 1)\n",
    "ta2 = np.nanmean(ta1,axis = 1)\n",
    "ta2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2792fe5e-9e71-46c5-b3ed-da2a7ec18b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_f = np.reshape(ta2,(20,608))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79e7377b-abd0-4629-a773-5a6e14d9baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##SSW Averaging Timelines\n",
    "ssw_wind = np.empty((12,143))\n",
    "ssw_wind[:] = np.nan\n",
    "\n",
    "ssw_rat = np.empty((12,143))\n",
    "ssw_rat[:] = np.nan\n",
    "\n",
    "ssw_size = np.empty((12,143))\n",
    "ssw_size[:] = np.nan\n",
    "\n",
    "ssw_cenl = np.empty((12,143))\n",
    "ssw_cenl[:] = np.nan\n",
    "\n",
    "ssw_ep= np.empty((12,143))\n",
    "ssw_ep[:] = np.nan\n",
    "\n",
    "ssw_t= np.empty((12,143))\n",
    "ssw_t[:] = np.nan\n",
    "\n",
    "for i in range(len(year)):\n",
    "    d1 = int(dates[i][0])\n",
    "    d2 = int(dates[i][1])\n",
    "    \n",
    "    ##diagnostics\n",
    "    \n",
    "    w = wind10[sswcl[i],d1:d2] #wind\n",
    "    ssw_wind[i] = w[:]\n",
    "    \n",
    "    rat = rat10[sswcl[i],d1:d2]\n",
    "    ssw_rat[i] = rat[:]\n",
    "    \n",
    "    cl = cenlat10[sswcl[i],d1:d2]\n",
    "    ssw_cenl[i] = cl[:]\n",
    "    \n",
    "    sz = size10[sswcl[i],d1:d2]\n",
    "    ssw_size[i] = sz[:]\n",
    "    \n",
    "    ep = ephi10[sswcl[i],d1:d2]\n",
    "    ssw_ep[i] = ep[:]\n",
    "    \n",
    "    tm = tm_f[sswcl[i],d1:d2]\n",
    "    ssw_t[i] = tm[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c151e-da06-42a7-a251-03772f20d1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 August 2021 Environment",
   "language": "python",
   "name": "aug21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
