{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "778542d6-56ce-40b8-a38f-e321acdcd35d",
   "metadata": {},
   "source": [
    "### *Trumpet Sound* \n",
    "Elena graduated Magna Cum Laude from Silly Goose University and needs to redo all her regression analysis with lagged temperature because she forgot to do it in the first place.\n",
    "\n",
    "#### Let's do Regression Analysis again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfb4ed95-a43d-428b-950b-2245d687b0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##relevant import statements\n",
    "import numpy as np\n",
    "import math\n",
    "import xarray as xr \n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f8c8b8e-22d4-4597-b2c2-7a7fdca55951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pickle files for gph\n",
    "infile = open(\"../AnomERAVals/cap_gphanom.p\", 'rb')\n",
    "gp1 = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "## load files for SFC, 2m Temp\n",
    "infile = open(\"../TemperatureGroupings/gl_SFCanom.p\", 'rb')\n",
    "tmp1 = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../TemperatureGroupings/cap_SFCanom.p\", 'rb')\n",
    "tmc1 = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../TemperatureGroupings/e_SFCanom.p\", 'rb')\n",
    "tme1 = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../EOFs/ehf100_latavg.p\", 'rb')\n",
    "ehf1 = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b72a925-21c8-408c-a400-4d83f066b4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "##this is a wrapper function I got from \n",
    "#https://stackoverflow.com/questions/41045752/using-statsmodel-estimations-with-scikit-learn-cross-validation-is-it-possible\n",
    "##the purpose of including this is to cross validate models \n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class SMWrapper(BaseEstimator, RegressorMixin):\n",
    "    \"\"\" A universal sklearn-style wrapper for statsmodels regressors \"\"\"\n",
    "    def __init__(self, model_class, fit_intercept=True):\n",
    "        self.model_class = model_class\n",
    "        self.fit_intercept = fit_intercept\n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = sm.add_constant(X)\n",
    "        self.model_ = self.model_class(y, X)\n",
    "        self.results_ = self.model_.fit()\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = sm.add_constant(X)\n",
    "        return self.results_.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e140f1-1417-4dbb-baca-df139fc7d211",
   "metadata": {},
   "source": [
    "**Modify gph/temp data files into xarray.** \n",
    "\n",
    "I am going to be utilizing cap (60-90N) gph anomalies (i.e. NAM values in strat, lol) and temperature anomalies over the great lakes region (an area of large significance). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f0695bf-799a-41b9-b312-f49a90e22f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reduce temperature \n",
    "tmp1 = np.nanmean(tmp1, axis = 1)\n",
    "tmp1 = np.nanmean(tmp1, axis = 1) ##avg temp anomaly over great lakes\n",
    "\n",
    "tmc1 = np.nanmean(tmc1, axis = 1)\n",
    "tmc1 = np.nanmean(tmc1, axis = 1) ##avg temp anomaly over cap\n",
    "\n",
    "tme1 = np.nanmean(tme1, axis = 1)\n",
    "tme1 = np.nanmean(tme1, axis = 1) ##avg temp anomaly over europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1897ce4-f078-41ef-bb4f-af276b835cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp1.reshape((40,608))\n",
    "tmc = tmc1.reshape((40,608))\n",
    "tme = tme1.reshape((40,608))\n",
    "gp = gp1.reshape((40,608))\n",
    "ehf = ehf1.reshape((40,608))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3fcb44-56e7-4f5c-b133-f761950ac403",
   "metadata": {},
   "source": [
    "**Import elliptical diagnostic values.**\n",
    "\n",
    "All at 10-hPa: zonal-mean zonal wind, ephi, size, ratio, central lat/lon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0134f657-2c2a-4ef6-bb8e-54a8437cfc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open(\"../New_EllipseVals/ephi10_79.p\", 'rb')\n",
    "ephi10 = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../New_EllipseVals/ephi_ratio10_79.p\", 'rb')\n",
    "rat10 = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../New_EllipseVals/ephi_size10_79.p\", 'rb')\n",
    "size10 = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../New_EllipseVals/ephi_cenlat10_79.p\", 'rb')\n",
    "cenlat10 = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../New_EllipseVals/ephi_cenlon10_79.p\", 'rb')\n",
    "cenlon10 = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../New_EllipseVals/ephi_wind10_79.p\", 'rb')\n",
    "wind10 = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9307e0b0-dc4d-448e-a8cf-e33bf90323b7",
   "metadata": {},
   "source": [
    "**Reduce datasets for lagging.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cca7e694-4c18-4ed8-821a-58eecea9ff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "##EOF date deletions \n",
    "ephi10 = np.delete(ephi10,[480,481,482,483,605,606,607],1)\n",
    "rat10 = np.delete(rat10,[480,481,482,483,605,606,607],1)\n",
    "size10 = np.delete(size10,[480,481,482,483,605,606,607],1)\n",
    "cenlat10 = np.delete(cenlat10,[480,481,482,483,605,606,607],1)\n",
    "cenlon10 = np.delete(cenlon10,[480,481,482,483,605,606,607],1)\n",
    "wind10 = np.delete(wind10,[480,481,482,483,605,606,607],1)\n",
    "gp = np.delete(gp,[480,481,482,483,605,606,607],1)\n",
    "eh = np.delete(ehf,[480,481,482,483,605,606,607],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a9da767c-d6b3-47ea-9228-0c73f315469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = np.delete(tme,[480,481,482,483,605,606,607],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0301a515-006a-4dbc-94e3-c7d8ab442638",
   "metadata": {},
   "outputs": [],
   "source": [
    "##10 day lag\n",
    "w10 = np.empty((40,561))\n",
    "e10 = np.empty((40,561))\n",
    "s10 = np.empty((40,561))\n",
    "r10 = np.empty((40,561))\n",
    "ct10 = np.empty((40,561))\n",
    "cn10 = np.empty((40,561))\n",
    "g10 = np.empty((40,561))\n",
    "eh10 = np.empty((40,561))\n",
    "\n",
    "t10 = np.empty((40,561))\n",
    "\n",
    "for i in range(0,40,1):\n",
    "    w10[i,:] = wind10[i,:561]\n",
    "    e10[i,:] = ephi10[i,:561]\n",
    "    s10[i,:] = size10[i,:561]\n",
    "    r10[i,:] = rat10[i,:561]\n",
    "    ct10[i,:] = cenlat10[i,:561]\n",
    "    cn10[i,:] = cenlon10[i,:561]\n",
    "    g10[i,:] = gp[i,:561]\n",
    "    eh10[i,:] = eh[i,:561]\n",
    "    \n",
    "    t10[i,:] = tp[i,40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4433e43d-c922-4db0-949c-72303b39ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##14 day lag\n",
    "w14 = np.empty((40,545))\n",
    "e14 = np.empty((40,545))\n",
    "s14 = np.empty((40,545))\n",
    "r14 = np.empty((40,545))\n",
    "ct14 = np.empty((40,545))\n",
    "cn14 = np.empty((40,545))\n",
    "g14 = np.empty((40,545))\n",
    "eh14 = np.empty((40,545))\n",
    "\n",
    "t14 = np.empty((40,545))\n",
    "\n",
    "for i in range(0,40,1):\n",
    "    w14[i,:] = wind10[i,:545]\n",
    "    e14[i,:] = ephi10[i,:545]\n",
    "    s14[i,:] = size10[i,:545]\n",
    "    r14[i,:] = rat10[i,:545]\n",
    "    ct14[i,:] = cenlat10[i,:545]\n",
    "    cn14[i,:] = cenlon10[i,:545]\n",
    "    g14[i,:] = gp[i,:545]\n",
    "    eh14[i,:] = eh[i,:545]\n",
    "    \n",
    "    t14[i,:] = tp[i,56:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4c5ede4d-00e0-4224-9083-be6712d25efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##20 day lag\n",
    "w20 = np.empty((40,521))\n",
    "e20 = np.empty((40,521))\n",
    "s20 = np.empty((40,521))\n",
    "r20 = np.empty((40,521))\n",
    "ct20 = np.empty((40,521))\n",
    "cn20 = np.empty((40,521))\n",
    "g20 = np.empty((40,521))\n",
    "eh20 = np.empty((40,521))\n",
    "\n",
    "t20 = np.empty((40,521))\n",
    "\n",
    "for i in range(0,40,1):\n",
    "    w20[i,:] = wind10[i,:521]\n",
    "    e20[i,:] = ephi10[i,:521]\n",
    "    s20[i,:] = size10[i,:521]\n",
    "    r20[i,:] = rat10[i,:521]\n",
    "    ct20[i,:] = cenlat10[i,:521]\n",
    "    cn20[i,:] = cenlon10[i,:521]\n",
    "    g20[i,:] = gp[i,:521]\n",
    "    eh20[i,:] = eh[i,:521]\n",
    "    \n",
    "    t20[i,:] = tp[i,80:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d76bbc-d0d6-44a0-ab23-5ade53cfd5e9",
   "metadata": {},
   "source": [
    "**Reshape the arrays, but change for relevant lag in temp.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cc2334d2-d766-4983-8bb4-18be5b3922cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##10-day = 22440\n",
    "##14-day = 21800\n",
    "##20-day = 20840\n",
    "\n",
    "wind = np.reshape(w10, (22440))\n",
    "rat = np.reshape(r10, (22440))\n",
    "size = np.reshape(s10, (22440))\n",
    "cenlt = np.reshape(ct10, (22440))\n",
    "cenln = np.reshape(cn10, (22440))\n",
    "ephi = np.reshape(e10, (22440))\n",
    "t_gr = np.reshape(t10, (22440))\n",
    "ga = np.reshape(g10, (22440))\n",
    "ef = np.reshape(eh10, (22440))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d7f868-ed07-4112-8420-76f42a376807",
   "metadata": {},
   "source": [
    "**Start GLM.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ca184460-0610-49e8-bc5a-50e440a2b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'wind': np.ndarray.tolist(wind),\n",
    "        'ephi': np.ndarray.tolist(ephi),\n",
    "        'rat': np.ndarray.tolist(rat),\n",
    "        'size': np.ndarray.tolist(size),\n",
    "        'cenlat': np.ndarray.tolist(cenlt),\n",
    "        'cenlon': np.ndarray.tolist(cenln),\n",
    "        'temp': np.ndarray.tolist(t_gr),\n",
    "        'gph': np.ndarray.tolist(ga),\n",
    "        'ehf': np.ndarray.tolist(ef)\n",
    "        }\n",
    "#data \n",
    "df = pd.DataFrame(data)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "85ff3987-13af-4fd0-a3e2-0e0ad29e51ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wind</th>\n",
       "      <th>ephi</th>\n",
       "      <th>rat</th>\n",
       "      <th>size</th>\n",
       "      <th>cenlat</th>\n",
       "      <th>cenlon</th>\n",
       "      <th>temp</th>\n",
       "      <th>gph</th>\n",
       "      <th>ehf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-7.607124</td>\n",
       "      <td>64.984870</td>\n",
       "      <td>0.829363</td>\n",
       "      <td>-8.177967e+06</td>\n",
       "      <td>6.095619</td>\n",
       "      <td>36.846883</td>\n",
       "      <td>-1.978301</td>\n",
       "      <td>207.932691</td>\n",
       "      <td>-2.678660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-6.722288</td>\n",
       "      <td>66.087162</td>\n",
       "      <td>0.849560</td>\n",
       "      <td>-7.950858e+06</td>\n",
       "      <td>5.882967</td>\n",
       "      <td>34.425273</td>\n",
       "      <td>-2.244587</td>\n",
       "      <td>210.962110</td>\n",
       "      <td>-2.322106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7.791359</td>\n",
       "      <td>67.657673</td>\n",
       "      <td>0.864105</td>\n",
       "      <td>-8.164457e+06</td>\n",
       "      <td>5.644762</td>\n",
       "      <td>35.041044</td>\n",
       "      <td>-0.170321</td>\n",
       "      <td>223.942869</td>\n",
       "      <td>-2.087212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.207796</td>\n",
       "      <td>68.747039</td>\n",
       "      <td>0.827428</td>\n",
       "      <td>-7.914626e+06</td>\n",
       "      <td>5.180015</td>\n",
       "      <td>36.054731</td>\n",
       "      <td>-1.409875</td>\n",
       "      <td>226.498197</td>\n",
       "      <td>-0.137953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-7.431390</td>\n",
       "      <td>70.147659</td>\n",
       "      <td>0.818546</td>\n",
       "      <td>-8.010516e+06</td>\n",
       "      <td>4.400724</td>\n",
       "      <td>38.484884</td>\n",
       "      <td>-2.102687</td>\n",
       "      <td>237.731642</td>\n",
       "      <td>-1.195304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22435</th>\n",
       "      <td>12.578408</td>\n",
       "      <td>33.623076</td>\n",
       "      <td>-0.151223</td>\n",
       "      <td>1.065059e+06</td>\n",
       "      <td>9.842261</td>\n",
       "      <td>23.159728</td>\n",
       "      <td>-1.302477</td>\n",
       "      <td>-815.714388</td>\n",
       "      <td>6.895312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22436</th>\n",
       "      <td>11.738369</td>\n",
       "      <td>33.140352</td>\n",
       "      <td>-0.127211</td>\n",
       "      <td>1.171033e+06</td>\n",
       "      <td>9.622129</td>\n",
       "      <td>19.421689</td>\n",
       "      <td>-1.071524</td>\n",
       "      <td>-797.776156</td>\n",
       "      <td>4.603848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22437</th>\n",
       "      <td>10.178578</td>\n",
       "      <td>32.894044</td>\n",
       "      <td>-0.077716</td>\n",
       "      <td>5.507438e+05</td>\n",
       "      <td>10.129209</td>\n",
       "      <td>18.383886</td>\n",
       "      <td>4.212329</td>\n",
       "      <td>-776.976656</td>\n",
       "      <td>5.499161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22438</th>\n",
       "      <td>11.451901</td>\n",
       "      <td>32.329026</td>\n",
       "      <td>-0.047985</td>\n",
       "      <td>1.727976e+05</td>\n",
       "      <td>10.285739</td>\n",
       "      <td>20.839867</td>\n",
       "      <td>1.760024</td>\n",
       "      <td>-759.030367</td>\n",
       "      <td>3.447603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22439</th>\n",
       "      <td>8.056370</td>\n",
       "      <td>31.635115</td>\n",
       "      <td>-0.023119</td>\n",
       "      <td>1.295744e+05</td>\n",
       "      <td>9.845926</td>\n",
       "      <td>22.378824</td>\n",
       "      <td>-1.431507</td>\n",
       "      <td>-752.426607</td>\n",
       "      <td>3.033745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22069 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            wind       ephi       rat          size     cenlat     cenlon  \\\n",
       "0      -7.607124  64.984870  0.829363 -8.177967e+06   6.095619  36.846883   \n",
       "1      -6.722288  66.087162  0.849560 -7.950858e+06   5.882967  34.425273   \n",
       "2      -7.791359  67.657673  0.864105 -8.164457e+06   5.644762  35.041044   \n",
       "3      -7.207796  68.747039  0.827428 -7.914626e+06   5.180015  36.054731   \n",
       "4      -7.431390  70.147659  0.818546 -8.010516e+06   4.400724  38.484884   \n",
       "...          ...        ...       ...           ...        ...        ...   \n",
       "22435  12.578408  33.623076 -0.151223  1.065059e+06   9.842261  23.159728   \n",
       "22436  11.738369  33.140352 -0.127211  1.171033e+06   9.622129  19.421689   \n",
       "22437  10.178578  32.894044 -0.077716  5.507438e+05  10.129209  18.383886   \n",
       "22438  11.451901  32.329026 -0.047985  1.727976e+05  10.285739  20.839867   \n",
       "22439   8.056370  31.635115 -0.023119  1.295744e+05   9.845926  22.378824   \n",
       "\n",
       "           temp         gph       ehf  \n",
       "0     -1.978301  207.932691 -2.678660  \n",
       "1     -2.244587  210.962110 -2.322106  \n",
       "2     -0.170321  223.942869 -2.087212  \n",
       "3     -1.409875  226.498197 -0.137953  \n",
       "4     -2.102687  237.731642 -1.195304  \n",
       "...         ...         ...       ...  \n",
       "22435 -1.302477 -815.714388  6.895312  \n",
       "22436 -1.071524 -797.776156  4.603848  \n",
       "22437  4.212329 -776.976656  5.499161  \n",
       "22438  1.760024 -759.030367  3.447603  \n",
       "22439 -1.431507 -752.426607  3.033745  \n",
       "\n",
       "[22069 rows x 9 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm = (df - df.mean())\n",
    "df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "11591d5c-1cb6-40ca-902e-68584fa21500",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_norm[['ephi','rat','cenlat','cenlon','size','wind','gph','ehf']]\n",
    "y = df_norm['temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "368b762e-44f6-4752-ad2f-99454217790f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  feature       VIF\n",
      "0    ephi  1.159822\n",
      "1     rat  1.434341\n",
      "2  cenlat  3.305233\n",
      "3  cenlon  1.086476\n",
      "4    size  3.347155\n",
      "5    wind  6.535029\n",
      "6     gph  4.380783\n",
      "7     ehf  1.214377\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "\n",
    "#VIF dataframe \n",
    "vif_data = pd.DataFrame() \n",
    "vif_data[\"feature\"] = x.columns \n",
    "  \n",
    "# calculating VIF for each feature \n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(x.values, i) \n",
    "                          for i in range(len(x.columns))] \n",
    "  \n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5fd98b47-fcae-4415-9a61-fed0dad426fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_norm[['ephi','rat','cenlat','cenlon','size','wind','gph','ehf']]\n",
    "y = df_norm['temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50721362-63a7-4bcf-b2a7-1844620ef274",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_norm[['wind']]\n",
    "y = df_norm['temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "57ddbd67-a0c7-4684-8be7-929de3eb380a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   temp   R-squared:                       0.023\n",
      "Model:                            OLS   Adj. R-squared:                  0.023\n",
      "Method:                 Least Squares   F-statistic:                     65.84\n",
      "Date:                Fri, 15 Dec 2023   Prob (F-statistic):          2.65e-107\n",
      "Time:                        17:32:19   Log-Likelihood:                -50143.\n",
      "No. Observations:               22069   AIC:                         1.003e+05\n",
      "Df Residuals:                   22060   BIC:                         1.004e+05\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -2.143e-16      0.016  -1.36e-14      1.000      -0.031       0.031\n",
      "ephi           0.0023      0.000      6.991      0.000       0.002       0.003\n",
      "rat           -0.0017      0.049     -0.035      0.972      -0.098       0.095\n",
      "cenlat        -0.0133      0.002     -6.484      0.000      -0.017      -0.009\n",
      "cenlon         0.0051      0.000     15.203      0.000       0.004       0.006\n",
      "size        4.085e-09   2.32e-09      1.763      0.078   -4.57e-10    8.63e-09\n",
      "wind           0.0025      0.002      1.028      0.304      -0.002       0.007\n",
      "gph           -0.0005    6.7e-05     -7.805      0.000      -0.001      -0.000\n",
      "ehf           -0.0004      0.002     -0.245      0.806      -0.004       0.003\n",
      "==============================================================================\n",
      "Omnibus:                      503.893   Durbin-Watson:                   0.390\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              552.275\n",
      "Skew:                          -0.354   Prob(JB):                    1.19e-120\n",
      "Kurtosis:                       3.316   Cond. No.                     3.90e+07\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.9e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# with statsmodels\n",
    "x = sm.add_constant(x) # adding a constant\n",
    " \n",
    "model = sm.OLS(y, x).fit()\n",
    "predictions = model.predict(x) \n",
    " \n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2563fc-904d-4d30-90a3-41b04730d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = cross_validate(SMWrapper(sm.GLM), x, y, scoring='r2')\n",
    "print(\"Full Model %0.2f accuracy with a standard deviation of %0.2f\" % (mod['test_score'].mean(), mod['test_score'].std()))\n",
    "#print(\"Wind Model %0.2f accuracy with a standard deviation of %0.2f\" % (wd.mean(), wd.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b54cea9-6d23-4919-8102-bd6e77cb3741",
   "metadata": {},
   "source": [
    "#### Back to cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9850475-45d6-4159-bf61-1c1a86e7a953",
   "metadata": {},
   "outputs": [],
   "source": [
    "##first do the full model\n",
    "x1_temps = np.empty((40,20641))\n",
    "x1_temps[:] = np.nan\n",
    "\n",
    "for i in range(0,40,1):\n",
    "    test_wind = w20[i,:] \n",
    "    test_ephi = e20[i,:] \n",
    "    test_rat = r20[i,:] \n",
    "    test_cenlt = ct20[i,:] \n",
    "    test_cenln = cn20[i,:] \n",
    "    test_gph = g20[i,:]\n",
    "    test_ehf = eh20[i,:]\n",
    "    test_temp = t20[i,:] \n",
    "    \n",
    "    test_data = {'wind': np.ndarray.tolist(test_wind),\n",
    "                'ephi': np.ndarray.tolist(test_ephi),\n",
    "                'rat': np.ndarray.tolist(test_rat),\n",
    "                'cenlat': np.ndarray.tolist(test_cenlt),\n",
    "                'cenlon': np.ndarray.tolist(test_cenln),\n",
    "                'temp': np.ndarray.tolist(test_temp),\n",
    "                'gph': np.ndarray.tolist(test_gph),\n",
    "                'ehf': np.ndarray.tolist(test_ehf)\n",
    "                }\n",
    "    df_test = pd.DataFrame(data)\n",
    "    df_test = df.dropna()\n",
    "    \n",
    "\n",
    "    xx = df_test[['ephi','rat','cenlat','cenlon','size','wind','gph']]\n",
    "    yy = df_test['temp']\n",
    "    \n",
    "    train_wind = np.reshape(np.delete(w20,i,0),(20319,)) \n",
    "    train_ephi = np.reshape(np.delete(e20,i,0),(20319,)) \n",
    "    train_rat = np.reshape(np.delete(r20,i,0),(20319,))\n",
    "    train_cenlt = np.reshape(np.delete(ct20,i,0),(20319,)) \n",
    "    train_cenln = np.reshape(np.delete(cn20,i,0),(20319,))\n",
    "    train_temp = np.reshape(np.delete(t20,i,0),(20319,))\n",
    "    train_gph = np.reshape(np.delete(g20,i,0),(20319,))\n",
    "    train_ehf = np.reshape(np.delete(eh20,i,0),(20319,))\n",
    "    \n",
    "    train_data = {'wind': np.ndarray.tolist(train_wind),\n",
    "                'ephi': np.ndarray.tolist(train_ephi),\n",
    "                'rat': np.ndarray.tolist(train_rat),\n",
    "                'cenlat': np.ndarray.tolist(train_cenlt),\n",
    "                'cenlon': np.ndarray.tolist(train_cenln),\n",
    "                'temp': np.ndarray.tolist(train_temp),\n",
    "                'gph': np.ndarray.tolist(train_gph),\n",
    "                'ehf': np.ndarray.tolist(train_ehf)\n",
    "                }\n",
    "    #data \n",
    "    df_train = pd.DataFrame(data)\n",
    "    df_train = df.dropna()\n",
    "\n",
    "    x1 = df_train[['ephi','rat','cenlat','cenlon','size','wind','gph']]\n",
    "    y1 = df_train['temp']\n",
    "    \n",
    "\n",
    "    # with statsmodels\n",
    "    x1 = sm.add_constant(x1)\n",
    "    xx = sm.add_constant(xx)# adding a constant\n",
    " \n",
    "    model = sm.OLS(y1, x1).fit()\n",
    "    prediction = model.predict(xx)\n",
    "    pred = prediction.reset_index(drop=True)\n",
    "    x1_temps[i,:] = pred.values[:]\n",
    "    #print_model = model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9c9b81-8ca7-44b1-9e23-10102f0b168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_temps = np.empty((40,20641))\n",
    "x2_temps[:] = np.nan\n",
    "\n",
    "for i in range(0,40,1):\n",
    "    test_wind = w20[i,:]  \n",
    "    test_temp = t20[i,:] \n",
    "    \n",
    "    test_data = {'wind': np.ndarray.tolist(test_wind),\n",
    "                'temp': np.ndarray.tolist(test_temp)\n",
    "                }\n",
    "    df_test = pd.DataFrame(data)\n",
    "    df_test = df.dropna()\n",
    "    \n",
    "\n",
    "    xx = df_test[['wind']]\n",
    "    yy = df_test['temp']\n",
    "    \n",
    "    train_wind = np.reshape(np.delete(w20,i,0),(20319,)) \n",
    "    train_temp = np.reshape(np.delete(t20,i,0),(20319,))\n",
    "    \n",
    "    train_data = {'wind': np.ndarray.tolist(train_wind),\n",
    "                'temp': np.ndarray.tolist(train_temp)\n",
    "                }\n",
    "    #data \n",
    "    df_train = pd.DataFrame(data)\n",
    "    df_train = df.dropna()\n",
    "    \n",
    "\n",
    "    x1 = df_train[['wind']]\n",
    "    y1 = df_train['temp']\n",
    "    \n",
    "\n",
    "    # with statsmodels\n",
    "    x1 = sm.add_constant(x1)\n",
    "    xx = sm.add_constant(xx)# adding a constant\n",
    " \n",
    "    model = sm.OLS(y1, x1).fit()\n",
    "    prediction = model.predict(xx)\n",
    "    pred = prediction.reset_index(drop=True)\n",
    "    x2_temps[i,:] = pred.values[:]\n",
    "    #print_model = model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663da8ef-e699-4357-89c7-a5c3ac5ccccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6eb3b9-a45a-44a1-9eea-26451af13218",
   "metadata": {},
   "outputs": [],
   "source": [
    "##calculate R2 for full model\n",
    "r2 = []\n",
    "for i in range(0,40,1):\n",
    "    rss= []\n",
    "    tss= []\n",
    "    #print(i)\n",
    "    for j in range(0,20641,1):\n",
    "        #print(j)\n",
    "        #print(x1_temps[i,j])\n",
    "        rs= (y.values[j]-x1_temps[i,j])**2\n",
    "        ts= (y.values[j]-np.mean(y.values[:]))**2\n",
    "        rss.append(rs)\n",
    "        tss.append(ts)\n",
    "    r = 1 - (np.sum(rs)/np.sum(ts))\n",
    "    r2.append(r)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f45ec0-f905-496a-8980-ea46d9da3f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "##calculate R2 for Wind-Only Model\n",
    "r2_wind = []\n",
    "for i in range(0,40,1):\n",
    "    rss= []\n",
    "    tss= []\n",
    "    #print(i)\n",
    "    for j in range(0,20641,1):\n",
    "        #print(j)\n",
    "        #print(x1_temps[i,j])\n",
    "        rs= (y.values[j]-x2_temps[i,j])**2\n",
    "        ts= (y.values[j]-np.mean(y.values[:]))**2\n",
    "        rss.append(rs)\n",
    "        tss.append(ts)\n",
    "    r = 1 - (np.sum(rs)/np.sum(ts))\n",
    "    r2_wind.append(r)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c42f3cb-1c2f-4bc7-8eb7-d6f134daf3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The R2 of my full model with cross validation is \", np.mean(r2))\n",
    "print(\"The R2 of my wind-only model with cross validation is \", np.mean(r2_wind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f681440-1927-442b-98d4-af540d0418ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 August 2023 Environment",
   "language": "python",
   "name": "aug23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
