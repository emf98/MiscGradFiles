{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "technical-chapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.feature\n",
    "from cartopy.util import add_cyclic_point\n",
    "import cartopy.crs as ccrs\n",
    "import xarray as xr\n",
    "import math\n",
    "import netCDF4\n",
    "#from get_ellipse_metrics import get_emetrics_max_min\n",
    "from fitEllipse2_new import fitEllipseContour\n",
    "from geopy.distance import great_circle\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib import cm #colormaps!\n",
    "import copy\n",
    "import os\n",
    "import scipy.stats\n",
    "import pickle\n",
    "\n",
    "#os.environ['DISPLAY']=':0.0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "frank-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define functions first:\n",
    "def point_inside_polygon(x,y,xarr,yarr):\n",
    "\n",
    "\tn = len(xarr)\n",
    "\tinside =False\n",
    "\n",
    "\tp1x = xarr[0]\n",
    "\tp1y = yarr[0]\n",
    "\tfor i in range(n+1):\n",
    "\t\tp2x,p2y = xarr[i % n],yarr[i % n]\n",
    "\t\tif y > min(p1y,p2y):\n",
    "\t\t\tif y <= max(p1y,p2y):\n",
    "\t\t\t\tif x <= max(p1x,p2x):\n",
    "\t\t\t\t\tif p1y != p2y:\n",
    "\t\t\t\t\t\txinters = (y-p1y)*(p2x-p1x)/(p2y-p1y)+p1x\n",
    "\t\t\t\t\tif p1x == p2x or x <= xinters:\n",
    "\t\t\t\t\t\tinside = not inside\n",
    "\t\tp1x,p1y = p2x,p2y\n",
    "\n",
    "\treturn inside;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "frank-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The main code begins here....\n",
    "home_dir = '/home11/grad/2020/ef935217/Research/Ellipses/'  # <----Change this \n",
    "lev_list = [10,50,30]\n",
    "temp_lev = [850]\n",
    "#contour_list = [31500,20000,23000]\n",
    "contour_list = [30000,20000,23000]\n",
    "\n",
    "write_out = True #write the ellipse data to a text file, True or False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### temperature avg matrices\n",
    "tmeanfile = xr.open_dataset(\"/erai/climo/mean/t.mean.climo.nc\")\n",
    "print(tmeanfile)\n",
    "tmeandata = np.array(tmeanfile.isel(lev=6, lat = 234).t) \n",
    "tmean = np.mean(tmeandata)\n",
    "print(tmean)\n",
    "##produces an annual\n",
    "\n",
    "save = np.empty((0,64,134))\n",
    "save_time = np.empty((0))\n",
    "year = [x for x in range(1999,2020)]\n",
    "print(\"850 temp data\")\n",
    "for i in range(len(year)-1):\n",
    "    print(\"#############\")\n",
    "    start1 = np.datetime64(str(year[i])+'-12-01T00:00:00')\n",
    "    stop1 = np.datetime64(str(year[i])+'-12-31T18:00:00')\n",
    "    t2file1 = xr.open_dataset(\"/erai/\"+str(year[i])+\"/t.\"+str(year[i])+\".nc\")\n",
    "    t2_file1 = t2file1[\"t\"] \n",
    "    t2_data1= t2_file1.loc[dict(time=slice(start1,stop1),lat=slice(19.5,64.86),lon=slice(198.24,292),lev=temp_lev)].squeeze(dim=\"lev\")\n",
    "    \n",
    "    start2 = np.datetime64(str(year[i+1])+'-01-01T00:00:00')\n",
    "    stop2 = np.datetime64(str(year[i+1])+'-03-31T18:00:00')\n",
    "    t2file2 = xr.open_dataset(\"/erai/\"+str(year[i+1])+\"/t.\"+str(year[i+1])+\".nc\")\n",
    "\n",
    "    t2_file2 = t2file2[\"t\"] \n",
    "    t2_data2= t2_file2.loc[dict(time=slice(start2,stop2),lat=slice(19.5,64.86),lon=slice(198.24,292),lev=temp_lev)].squeeze(dim=\"lev\")\n",
    "    \n",
    "    print(year[i])\n",
    "    tlats_era = t2_data2[\"lat\"].values\n",
    "    print(\"lats\")\n",
    "    print(len(tlats_era))\n",
    "    tlons_era = t2_data2[\"lon\"].values\n",
    "    print(\"lons\")\n",
    "    print(len(tlons_era))\n",
    "    \n",
    "    tempv = np.concatenate([t2_data1[:, :, :], t2_data2[:, :, :]],axis=0)\n",
    "    print(tempv.shape)\n",
    "    y = np.full((len(tempv[:,0,0])),year[i])\n",
    "    save = np.concatenate([save,tempv],axis=0)\n",
    "    save_time = np.concatenate([save_time,y])\n",
    "    print(\"SHAPE)\")\n",
    "    print(save.shape)\n",
    "    \n",
    "    #if len(tempv[:,0,0]) == 484:\n",
    "        #tst = np.zeros((4,64,134))\n",
    "        #times = [str(year[i+1])+'-02-29T00:00:00', str(year[i+1])+'-02-29T06:00:00', str(year[i+1])+'-02-29T12:00:00', str(year[i+1])+'-02-29T18:00:00']\n",
    "        #test = xr.DataArray(tst, coords = [times,tlats_era, tlons_era], dims=[\"time\", \"lat\", \"lon\"])\n",
    "        #print(test)\n",
    "        #tempvs = xr.concat([tempv[:, :, :],test[:, :, :]], dim=\"time\")\n",
    "        #tempvals[i,:,:,:] = tempvs[:,:,:]\n",
    "    #else: \n",
    "        #tempvals[i,:,:,:] = tempv[:,:,:]\n",
    "         \n",
    "\n",
    "t2lats = t2_data2['lat'].values\n",
    "t2lons = t2_data2['lon'].values\n",
    "print(t2lats)\n",
    "\n",
    "#print(tempvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "save.shape\n",
    "\n",
    "t2lats = t2_data2['lat'].values\n",
    "t2lons = t2_data2['lon'].values\n",
    "\n",
    "pickle.dump(t2lats, open(\"lats.p\",\"wb\"))\n",
    "pickle.dump(t2lons, open(\"lons.p\",\"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(1999,2018): \n",
    "    print(i)\n",
    "    year_save = save[np.where(save_time==i)]\n",
    "    print(year_save.shape)\n",
    "    year_save = np.average(year_save,axis=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e018fbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(save_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(save_time, open(\"save_time.p\",\"wb\"))\n",
    "\n",
    "pickle.dump(save, open(\"save.p\",\"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "ephi_ratio10 = np.empty((20,488))\n",
    "ephi_ratio10[:] = np.nan\n",
    "ephi_wind10 = np.empty((20,488))\n",
    "ephi_wind10[:] = np.nan\n",
    "ephi_cenlat10 = np.empty((20,488))\n",
    "ephi_cenlat10[:] = np.nan\n",
    "ephi_size10 = np.empty((20,488))\n",
    "ephi_size10[:] = np.nan\n",
    "ephi10 = np.empty((20,488))\n",
    "ephi10[:] = np.nan\n",
    "\n",
    "ephi_ratio30 = np.empty((20,488))\n",
    "ephi_ratio30[:] = np.nan\n",
    "ephi_wind30 = np.empty((20,488))\n",
    "ephi_wind30[:] = np.nan\n",
    "ephi_cenlat30 = np.empty((20,488))\n",
    "ephi_cenlat30[:] = np.nan\n",
    "ephi_size30 = np.empty((20,488))\n",
    "ephi_size30[:] = np.nan\n",
    "ephi30 = np.empty((20,488))\n",
    "ephi30[:] = np.nan\n",
    "\n",
    "ephi_ratio50 = np.empty((20,488))\n",
    "ephi_ratio50[:] = np.nan\n",
    "ephi_wind50 = np.empty((20,488))\n",
    "ephi_wind50[:] = np.nan\n",
    "ephi_cenlat50 = np.empty((20,488))\n",
    "ephi_cenlat50[:] = np.nan\n",
    "ephi_size50 = np.empty((20,488))\n",
    "ephi_size50[:] = np.nan\n",
    "ephi50 = np.empty((20,488))\n",
    "ephi50[:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "personalized-expense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "### Read in the data\n",
    "## This must have a time component, or else fhr_inc<24h won't work.\n",
    "\n",
    "year = 2013\n",
    "month = 3\n",
    "day = 1\n",
    "date1 = dt.datetime(year,month,day,0)  #first date to plot\n",
    "total_days = 31\n",
    "first_fhr = 0\n",
    "hours = total_days * 24\n",
    "hr_inc = 6\n",
    "times = [date1 + dt.timedelta(hours=x) for x in range(0,hours,hr_inc)]\n",
    "date_list = netCDF4.date2num(times,units=\"hours since 1800-01-01 00:00:00\",calendar=\"gregorian\") #change dates to netcdf times\n",
    "\n",
    "\n",
    "windlat = 60.0\n",
    "\n",
    "#For real time plots...\n",
    "#today = dt.datetime.utcnow()-dt.timedelta(days=0)   ### changed this to 0 day delay\n",
    "#today = today.replace(hour=0,minute=0,second=0,microsecond=0)\n",
    "#day_str = today.strftime(\"%Y%m%d\")\n",
    "#day_label = today.strftime(\"Init: %a %b %d %Y %H%M UTC\")\n",
    "#first_fhr = 0\n",
    "#last_fhr = 384\n",
    "#fhr_inc = 6\n",
    "#fhr_list = np.arange(first_fhr,last_fhr+fhr_inc,fhr_inc)\n",
    "\n",
    "  \n",
    "metric_list = [\"cenlat\",\"cenlon\",\"ratio\",\"phi\",\"area\",\"u\",\"t\"]\n",
    "min_data = {}\n",
    "max_data = {}\n",
    "avg_data = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "abandoned-election",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening ERAI data 10 and controur level 30000\n",
      "Partitioning and averaging data.\n",
      "First, g data\n",
      "u data\n",
      "t data\n",
      "lat and lon\n",
      "level: 10\n",
      "date: [1867872. 1867878. 1867884. 1867890. 1867896. 1867902. 1867908. 1867914.\n",
      " 1867920. 1867926. 1867932. 1867938. 1867944. 1867950. 1867956. 1867962.\n",
      " 1867968. 1867974. 1867980. 1867986. 1867992. 1867998. 1868004. 1868010.\n",
      " 1868016. 1868022. 1868028. 1868034. 1868040. 1868046. 1868052. 1868058.\n",
      " 1868064. 1868070. 1868076. 1868082. 1868088. 1868094. 1868100. 1868106.\n",
      " 1868112. 1868118. 1868124. 1868130. 1868136. 1868142. 1868148. 1868154.\n",
      " 1868160. 1868166. 1868172. 1868178. 1868184. 1868190. 1868196. 1868202.\n",
      " 1868208. 1868214. 1868220. 1868226. 1868232. 1868238. 1868244. 1868250.\n",
      " 1868256. 1868262. 1868268. 1868274. 1868280. 1868286. 1868292. 1868298.\n",
      " 1868304. 1868310. 1868316. 1868322. 1868328. 1868334. 1868340. 1868346.\n",
      " 1868352. 1868358. 1868364. 1868370. 1868376. 1868382. 1868388. 1868394.\n",
      " 1868400. 1868406. 1868412. 1868418. 1868424. 1868430. 1868436. 1868442.\n",
      " 1868448. 1868454. 1868460. 1868466. 1868472. 1868478. 1868484. 1868490.\n",
      " 1868496. 1868502. 1868508. 1868514. 1868520. 1868526. 1868532. 1868538.]\n",
      "t2data\n",
      "##########################\n",
      "1867872.0\n",
      "Date 00 UTC 01 Feb 2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kt11/ktyle/anaconda3_2001/envs/jun20/lib/python3.7/site-packages/ipykernel_launcher.py:83: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "/kt11/ktyle/anaconda3_2001/envs/jun20/lib/python3.7/site-packages/ipykernel_launcher.py:86: DeprecationWarning: The outline_patch property is deprecated. Use GeoAxes.spines['geo'] or the default Axes properties instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(18000, 33500, 250)\n",
      "in try\n",
      "Number of ellipses:  2\n",
      "in elipse ...\n",
      "Number of ellipses:  2\n",
      "Diffs lat/lon:  22.35550423480916 0.0\n",
      "It is False that the contour includes the pole\n",
      "Point didn't include pole - keeping these to add to next set\n",
      "Diffs lat/lon:  22.174887169032246 0.0\n",
      "It is False that the contour includes the pole\n",
      "Point didn't include pole - add to these to previous set\n",
      "Running ellipse diagnostic now\n",
      "old center = [ 0.1708794  -0.07524216]\n",
      "old angle of rotation = 15.61660639652037\n",
      "old axes = [0.11401959 0.19726033]\n",
      "center = [ 0.1708794  -0.07524216]\n",
      "angle of rotation = -74.38339360347965\n",
      "axes = [0.19726033 0.11401959]\n",
      "0.19726033482979421 0.11401958658334249 0.17087939692957796 -0.07524216318147933 -1.2982351271876091\n",
      "Center of ellipse: 68.84799839918159 N -23.765007138523668 E\n",
      "Emetrics phi: -74.38339360347963\n",
      "right before savefig\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 122] Disk quota exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-bf6ca9167b14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mplot_lev\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m                         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplots_loc10\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34mf\"{plot_label}_{plot_lev}hpa.png\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mplot_lev\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplots_loc30\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34mf\"{plot_label}_{plot_lev}hpa.png\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kt11/ktyle/anaconda3_2001/envs/jun20/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kt11/ktyle/anaconda3_2001/envs/jun20/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   2201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kt11/ktyle/anaconda3_2001/envs/jun20/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2124\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2125\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2126\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2127\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2128\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kt11/ktyle/anaconda3_2001/envs/jun20/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m                 _png.write_png(renderer._renderer, fh, self.figure.dpi,\n\u001b[0;32m--> 537\u001b[0;31m                                metadata={**default_metadata, **metadata})\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_to_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kt11/ktyle/anaconda3_2001/envs/jun20/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kt11/ktyle/anaconda3_2001/envs/jun20/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mopen_file_cm\u001b[0;34m(path_or_file, mode, encoding)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 122] Disk quota exceeded"
     ]
    }
   ],
   "source": [
    "for plot_lev,the_contour in zip(lev_list,contour_list): #loop through each level\n",
    "\tprint(\"Opening ERAI data \"+str(plot_lev)+\" and controur level \"+str(the_contour)  )\n",
    "\t\n",
    "\trat = []\n",
    "\tcenl = []\n",
    "\twind = []\n",
    "\tsz = []\n",
    "\tep = []\n",
    "\t\n",
    "\tplots_loc10 = \"./POR_Images/10hPa/2012/\"   ##<-- Where are you saving the plot files?\n",
    "\tplots_loc30 = \"./POR_Images/30hPa/2012/\" \n",
    "\tplots_loc50 = \"./POR_Images/50hPa/2012/\" \n",
    "#\ttext_file = \"./\"+date1.strftime(\"%Y%m%d_%H%M\")+\"_\"+str(plot_lev)+\".txt\"   ##<-- Where are you saving text files?\n",
    "#\tfout = open(text_file,'w')\n",
    "    ##temp text\n",
    "\ttext_file2 = \"./\"+date1.strftime(\"%Y%m%d_%H%M\")+\"_temp\"+str(plot_lev)+\".txt\"  \n",
    "\tfout2 = open(text_file2,'w')\n",
    "\tif plot_lev == 10:\n",
    " \n",
    "\t\tgfile = xr.open_dataset(\"/erai/\"+str(year)+\"/g.\"+str(year)+\".nc\")\n",
    "\t\tg_files = gfile[\"g\"]\n",
    "\t\ttfile = xr.open_dataset(\"/erai/\"+str(year)+\"/t.\"+str(year)+\".nc\")\n",
    "\t\tt_files = tfile[\"t\"]\n",
    "\t\tufile = xr.open_dataset(\"/erai/\"+str(year)+\"/u.\"+str(year)+\".nc\")\n",
    "\t\tu_files = ufile[\"u\"]\n",
    "\n",
    "\n",
    "\t\tprint(\"Partitioning and averaging data.\")\n",
    "\t\tprint(\"First, g data\")\n",
    "\t\tg_data = g_files.loc[dict(lat=slice(0,90),lev=lev_list)]\n",
    "\t\tprint(\"u data\")\n",
    "\t\tu_data = u_files.loc[dict(lat=slice(windlat-1,windlat+1),lev=lev_list)].mean(dim='lon')\n",
    "\t\tprint(\"t data\")        \n",
    "\t\tt_data = t_files.loc[dict(lat=slice(75,90),lev=lev_list)]\n",
    "\t\ttlats = t_data['lat'].values\n",
    "\t\tweights=np.cos(np.deg2rad(t_data.lat))\n",
    "\t\tweights.name = \"weights\"\n",
    "\n",
    "        \n",
    "#hgt_250, lon = cutil.add_cyclic_point(data_hght.variables['Geopotential_height_isobaric'][:],coord=lon)\n",
    "\t\tprint(\"lat and lon\")\n",
    "\t\tlats_era = g_data[\"lat\"].values\n",
    "\t\tlons_era = g_data[\"lon\"].values\n",
    "\n",
    "        \n",
    "\tprint(f\"level: {plot_lev}\")\n",
    "\n",
    "\tfor date in date_list: #loop through each day \n",
    "\t\tprint(f\"date: {date_list}\")\n",
    "\t\tind = np.where(date_list == date)[0]\n",
    "\t\tfor d in ind:\n",
    "\t\t\tt = d\n",
    "\t\t\theight = g_data.loc[dict(time=times[t],lev=plot_lev)]\n",
    "\t\t\tu = u_data.loc[dict(time=times[t],lev=plot_lev)].mean(dim='lat')\n",
    "\t\t\ttdata = t_data.loc[dict(time=times[t],lev=plot_lev)].mean(dim='lon')   \n",
    "\t\t\t#tdata2 = t2_data.loc[dict(time=times[t])]\n",
    "\t\ttemp = tdata.weighted(weights).mean(dim='lat')\n",
    "        \n",
    "\t\tprint(\"t2data\")\n",
    "\t\t#print(tdata2)\n",
    "\t\t#stop\n",
    "\t\t#td2 = tdata2.values\n",
    "\t\t#for i in range(len(td2[:,1])):\n",
    "\t\t\t#fout2.write(str(td2[i,:])+'\\n')            \n",
    "\n",
    "              \n",
    "\t\tformatted_date = times[t].strftime(\"%Y%m%d\")\n",
    "\t\temark = []\n",
    "\t\teline = []\n",
    "\t\tcs_temp = []\n",
    "\t\t#mem_list = list[range(0,30),31]\n",
    "\t\t#mem_list.append(0)\n",
    "\t\t#mem_list.append(-1)\n",
    "\t\tprint(\"##########################\")\n",
    "\t\tprint(date)\n",
    "\t\tprint(\"Date \"+times[t].strftime(\"%H UTC %d %b %Y\"))\n",
    "\t\tvalid_label = (times[t].strftime(\"Valid: %H UTC %d %b %Y\"))\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tplt.Figure(figsize=(15,15),dpi=120)#figure(figsize=(12,12),dpi=1200) <---Set fig size here!\n",
    "\n",
    "\t\t#ax = plt.subplot(1,1,1,projection=ccrs.Orthographic(0,90))\n",
    "\t\tax = plt.axes(projection=ccrs.Orthographic(0,90))\n",
    "\t\tax.add_feature(cartopy.feature.LAND, zorder=1, edgecolor='dimgray',facecolor='none')\n",
    "\t\t#ax.set_extent([-180,180,0,90],ccrs.PlateCarree())\n",
    "\t\tax.outline_patch.set_edgecolor('none')\n",
    "\t\tgl = ax.gridlines(color=\"grey\",linestyle=\":\",linewidth=0.5)#=lat_lon_width)\n",
    "\n",
    "\t\tclevs = range(18000,33500,250)\n",
    "\n",
    "\t\t[x,y] = np.meshgrid(lons_era,lats_era)\n",
    "\t\t#[x2,y2] = np.meshgrid(tlons_era,tlats_era)\n",
    "\n",
    "\n",
    "\t\tplt.title(str(plot_lev)+\"hPa Elliptical Diagnostics\\n\"+valid_label)\n",
    "\n",
    "\t\tmem_color = \"blue\"\n",
    "\t\tmem_lw = 3.0\n",
    "\t\tmem_ms = 8\n",
    "\t\tcont_color = \"#aec2e2\"\n",
    "\t\tcont_lw = 1.0\n",
    "        \n",
    "\t\tcs_temp.append(ax.contour(x,y,height,levels=clevs,linewidths=cont_lw,colors=cont_color))\n",
    "\t\t\n",
    "\n",
    "\t\tline_w = np.array(clevs,dtype=np.float)\n",
    "\t\tfor i,c in enumerate(clevs):\n",
    "\t\t\tif c == the_contour:\n",
    "\t\t\t\tline_w[i] = 1.5 # Make the contour we're using for the ellipse calc fatter\n",
    "\t\t\telse:\n",
    "\t\t\t\tline_w[i] = 0.5\n",
    "\t\tprint(clevs)\n",
    "\n",
    "\t\tax.contour(x,y,height,clevs,transform=ccrs.PlateCarree(),extend='both',colors='black',linewidths=line_w)\n",
    "\t\t#ax.contour(x2,y2,tdata2, lev = [tmean], transform=ccrs.PlateCarree(),extend='both',colors='blue',linewidths=line_w)\n",
    "##NEED TO INCORPORATE THE CLIMATOLOGICAL MEAN TEMP LINE AT 850 MB\n",
    "\t\ttry:\n",
    "\t\t\tlev_contour_ind = np.where(np.array(cs_temp[-1].levels)==the_contour)[0][0]\n",
    "\t\t\tisoline_list = cs_temp[-1].allsegs[lev_contour_ind]\n",
    "\t\t\tprint(\"in try\")\n",
    "\t\t\tprint(\"Number of ellipses: \",len(isoline_list))                                \n",
    "\t\texcept:\n",
    "\t\t\tprint(\"Contours not found for\",the_contour,\"meter level at\",plot_lev,\"hPa.\")\n",
    "\t\t\tisoline_list = []        \n",
    "        \n",
    "\t\tif len(isoline_list) > 0:\n",
    "\t\t\tlev_contour_ind = np.where(np.array(cs_temp[-1].levels)==the_contour)[0][0]\n",
    "\t\t\tisoline_list = cs_temp[-1].allsegs[lev_contour_ind]\n",
    "\t\t\t#print(isoline_list)\n",
    "\t\t\tprint(\"in elipse ...\")\n",
    "\t\t\t#quit()\n",
    "\t\t\tprint(\"Number of ellipses: \",len(isoline_list))                                \n",
    "\t\telse:\n",
    "\t\t\tprint(\"Contours not found for\",the_contour,\"meter level at\",plot_lev,\"hPa.\")\n",
    "\t\t\tisoline_list = []\n",
    "\n",
    "\t\tisocount = 0\n",
    "\t\tsmall = 0\n",
    "\t\tratio1 = 0\n",
    "\t\tuvalues1 = 0\n",
    "\t\tcenlat1 = 0\n",
    "\t\tsize1 = 0\n",
    "\t\tephi1 = 0\n",
    "\t\t        \n",
    "\t\tfor isoline in isoline_list:\n",
    "\t\t\t#[iso_lon,iso_lat] = mm(isoline[:,0],isoline[:,1],inverse=True)\n",
    "\t\t\t[iso_lon,iso_lat] = [isoline[:,0],isoline[:,1]]\n",
    "\t\t\tif len(iso_lon)<15:\n",
    "\t\t\t\tprint(\"-----Not analyzing ellipse with\",len(iso_lon),\"points, continuing...\")  # Check for size!\n",
    "\t\t\t\tsmall = 1\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t# Checking to see if contours are closed (0) or need to be joined (1)  Checking before convert lat/lon to radians\n",
    "\t\t\tlon_diff = abs(iso_lon[0] - iso_lon[len(iso_lon)-1])\n",
    "\t\t\tlat_diff = abs(iso_lat[0] - iso_lat[len(iso_lat)-1])\n",
    "\t\t\tjoin = 0\n",
    "\t\t\tif lon_diff > 1 or lat_diff > 1:\n",
    "\t\t\t\tjoin = 1\n",
    "\t\t\t\tprint(\"Diffs lat/lon: \",lat_diff,lon_diff)\n",
    "\t\t\tiso_lon = np.deg2rad(iso_lon)\n",
    "\t\t\tiso_lat = np.deg2rad(iso_lat)\n",
    "\n",
    "\t\n",
    "\t\t\t## Now convert it into polar coordinates for ellipse math.\n",
    "\t\t\tex = np.array((np.cos(iso_lon)*np.cos(iso_lat))/(1+np.sin(iso_lat)))\n",
    "\t\t\tey = np.array((np.sin(iso_lon)*np.cos(iso_lat))/(1+np.sin(iso_lat)))\n",
    "\n",
    "\t\t\t## does this contour include the pole?\n",
    "\t\t\toverpole = point_inside_polygon(0,0,ex,ey)  #returns true if poly includes the pole, false if not \n",
    "\t\t\tprint(\"It is\",overpole, \"that the contour includes the pole\")\n",
    "\t\t\t   \n",
    "\t\t\t### contours break if they don't include the pole and need to be reconnected here...\n",
    "\t\t\t### first check that contour doesn't include pole, there is more than one contour,... \n",
    "\t\t\t###        ...the contours are not a real split vortex and we didn't get rid of one because it was small...\n",
    "\t\t\tif not overpole and len(isoline_list) > 1 and join > 0 and small < 1:\n",
    "\t\t\t\tif isocount > 0:\n",
    "\t\t\t\t\tex = np.append(ex,ex2)\n",
    "\t\t\t\t\tey = np.append(ey,ey2)\n",
    "\t\t\t\t\tprint(\"Point didn't include pole - add to these to previous set\")\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tex2 = ex\n",
    "\t\t\t\t\tey2 = ey\n",
    "\t\t\t\t\tprint(\"Point didn't include pole - keeping these to add to next set\")\n",
    "\t\t\t\t\tisocount = 1\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tprint(\"Running ellipse diagnostic now\")\n",
    "\t\t\texx,eyy,eaax,ebax,ecenterx,ecentery,ephi = fitEllipseContour(ex,ey)\n",
    "\t\t\t\n",
    "\t\t\t## Convert back to lat/lon \n",
    "\t\t\telons = np.where(exx<0,np.where(eyy>0,np.arctan(eyy/exx)+math.pi,np.arctan(eyy/exx)-math.pi),np.arctan(eyy/exx))\n",
    "\t\t\tyysinxxlon = eyy/np.sin(elons)\n",
    "\t\t\telats = -2*(np.arctan(yysinxxlon) - (math.pi/4.0))\n",
    "\t\t\telats = np.rad2deg(elats)\n",
    "\t\t\telons = np.rad2deg(elons)\n",
    "\t\n",
    "\t\t\t## Still not really sure what this is for...\n",
    "\t\t\tfor g in range(1,len(elats)):\n",
    "\t\t\t\tif abs(elats[g]-elats[g-1]) > 1.5:\n",
    "\t\t\t\t\telats[g] = elats[g-1]\n",
    "\t\n",
    "\t\t\t## Center points back to lat/lon\n",
    "\t\t\tcenlon = np.where(ecenterx<0,np.where(ecentery>0,np.arctan(ecentery/ecenterx)+math.pi,np.arctan(ecentery/ecenterx)-math.pi),np.arctan(ecentery/ecenterx))\n",
    "\t\t\tysinlon = ecentery/np.sin(cenlon)\n",
    "\t\t\tcenlat = np.rad2deg(-2 * (np.arctan(ysinlon) - (math.pi/4.0)))\n",
    "\t\t\tcenlon = np.rad2deg(cenlon)\n",
    "\t\t\tprint(\"Center of ellipse:\",cenlat,\"N\",cenlon,\"E\")\n",
    "\t\n",
    "\t\t\t## Calculate endpoints of the axes of the vortex, convert to lat/lon\n",
    "\t\t\txa = eaax * np.cos(ephi)\n",
    "\t\t\tya = eaax * np.sin(ephi)\n",
    "\t\t\txb = ebax * np.sin(ephi)\n",
    "\t\t\tyb = ebax * np.cos(ephi)\n",
    "\t\t\tendx = np.array([ecenterx+xa,ecenterx-xa,ecenterx+xb,ecenterx-xb])\n",
    "\t\t\tendy = np.array([ecentery+ya,ecentery-ya,ecentery-yb,ecentery+yb])\n",
    "\t\t\tendlon = np.where(endx < 0,np.where(endy>0,np.arctan(endy/endx)+math.pi,np.arctan(endy/endx)-math.pi),np.arctan(endy/endx))\n",
    "\t\t\tysinelon = endy/np.sin(endlon)\n",
    "\t\t\tendlat = np.rad2deg(-2 *(np.arctan(ysinelon) - (math.pi/4)))\n",
    "\t\t\tendlon = np.rad2deg(endlon)\n",
    "\t\n",
    "\t\t\t## Calc great circle distances; (still necessary?) \n",
    "\t\t\ta1gc = great_circle((endlat[0],endlon[0]),(cenlat,cenlon)).km\n",
    "\t\t\ta2gc = great_circle((cenlat,cenlon),(cenlat,endlat[1])).km\n",
    "\t\t\tb1gc = great_circle((endlat[2],endlon[2]),(cenlat,cenlon)).km\n",
    "\t\t\tb2gc = great_circle((cenlat,cenlon),(endlat[3],endlon[3])).km\n",
    "\n",
    "\t\t\tephi = np.rad2deg(ephi)\n",
    "\t\t\t## If a1 shorter than b1, adjust phi to correct the orientation angle\n",
    "\t\t\tif a1gc < b1gc:\n",
    "\t\t\t\tephi -= 90\n",
    "\t\t\tprint(\"Emetrics phi:\",ephi)\n",
    "\t\t\tif ephi < -45:\n",
    "\t\t\t\tephi += 180\n",
    "\t\t\t\n",
    "\t\t\tratio = a1gc/b1gc\n",
    "\t\t\tif ratio < 1.0:\n",
    "\t\t\t\tratio = 1.0/ratio\n",
    "\t\n",
    "\t\t\tsize = math.pi*a1gc*b1gc\n",
    "\t\t\testr = times[t].strftime(\"%H %Y%m%d%H\")+\" \"+f'{cenlon:.3f}'+\" \"+f'{cenlat:.3f}'+\" \"+f'{a1gc:.3f}'+\" \"+f'{b1gc:.3f}'+\" \"+f'{ephi:.3f}'+\" \"+f'{u.values:.3f}'+\" \"+f'{temp.values:.3f}'\n",
    "\t\t\t#if write_out:\n",
    "\t\t\t\t#fout.write(estr+\"\\n\")\n",
    "\n",
    "\t\t\texy=np.array(list(zip(elons,elats)))\n",
    "\t\t\tplt.plot(elons,elats,color='red',transform=ccrs.Geodetic(),linewidth=mem_lw)\n",
    "\t\t\tplt.plot(cenlon,cenlat,markersize=4,marker='o',color='red',transform=ccrs.PlateCarree())\n",
    "\t\t\t#ax.add_patch(Polygon(exy,closed=True,color='magenta',fill=False,lw=mem_lw,transform=ccrs.PlateCarree()))\n",
    "\t\t\tratio1 = ratio1+ratio\n",
    "\t\t\tuvalues1 = uvalues1+u.values\n",
    "\t\t\tcenlat1 = cenlat1+cenlat\n",
    "\t\t\tsize1 = size1+size\n",
    "\t\t\tephi1 = ephi1+ephi\n",
    "            \n",
    "\t\tif len(isoline_list) > 0:\n",
    "\t\t\trat.append(ratio1/len(isoline_list))\n",
    "\t\t\twind.append(uvalues1/len(isoline_list))\n",
    "\t\t\tcenl.append(cenlat1/len(isoline_list))\n",
    "\t\t\tsz.append(size1/len(isoline_list))\n",
    "\t\t\tep.append(ephi1/len(isoline_list))\n",
    "            \n",
    "\t\tif len(isoline_list) == 0:\n",
    "\t\t\trat.append(np.nan)\n",
    "\t\t\twind.append(np.nan)\n",
    "\t\t\tcenl.append(np.nan)\n",
    "\t\t\tsz.append(np.nan)\n",
    "\t\t\tep.append(np.nan)\n",
    "            \n",
    "\t\t#print(cenlon)\n",
    "\t\t#print(cenlat)\n",
    "\t\t#print(ephi)\n",
    "\t\tprint(\"right before savefig\")\n",
    "\t\tplot_label = times[t].strftime(\"%Y%m%d%H\")\n",
    "        \n",
    "\t\tif plot_lev == 10:\n",
    "\t\t\tplt.savefig(plots_loc10+f\"{plot_label}_{plot_lev}hpa.png\",format='png')            \n",
    "\t\tif plot_lev == 30:\n",
    "\t\t\tplt.savefig(plots_loc30+f\"{plot_label}_{plot_lev}hpa.png\",format='png')\n",
    "\t\tif plot_lev == 50:\n",
    "\t\t\tplt.savefig(plots_loc50+f\"{plot_label}_{plot_lev}hpa.png\",format='png')\n",
    "            \n",
    "\t\t#plt.savefig(plots_loc+\"ellipse\"+str(plot_lev)+\"_\"+str(fhr/6)+\".png\",format='png')\n",
    "\t\tprint(\"right after savefig\")\n",
    "\t\t#plt.close()\n",
    "\t\tplt.clf()\n",
    "\t\t#quit()\n",
    "#\tif plot_lev == 10:\n",
    "#\t\tephi_ratio10[19,364:] = rat[:]\n",
    "#\t\tephi_wind10[19,364:] = wind[:]\n",
    "#\t\tephi_cenlat10[19,364:] = cenl[:]\n",
    "#\t\tephi_size10[19,364:] = sz[:]\n",
    "#\t\tephi10[19,364:] = ep[:]\n",
    "\n",
    "#\tif plot_lev == 30:\n",
    "#\t\tephi_ratio30[19,364:] = rat[:]\n",
    "#\t\tephi_wind30[19,364:] = wind[:]\n",
    "#\t\tephi_cenlat30[19,364:] = cenl[:]\n",
    "#\t\tephi_size30[19,364:] = sz[:]\n",
    "#\t\tephi30[19,364:] = ep[:]\n",
    "\n",
    "            \n",
    "#\tif plot_lev == 50:\n",
    "#\t\tephi_ratio50[19,364:] = rat[:]\n",
    "#\t\tephi_wind50[19,364:] = wind[:]\n",
    "#\t\tephi_cenlat50[19,364:] = cenl[:]\n",
    "#\t\tephi_size50[19,364:] = sz[:]\n",
    "#\t\tephi50[19,364:] = ep[:]\n",
    "\t#quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ephi_ratio10, open(\"ephi_ratio10_1.p\", 'wb'))\n",
    "pickle.dump(ephi_wind10, open(\"ephi_wind10_1.p\", 'wb')) \n",
    "pickle.dump(ephi_cenlat10, open(\"ephi_cenlat10_1.p\", 'wb'))\n",
    "pickle.dump(ephi_size10, open(\"ephi_size10_1.p\", 'wb'))\n",
    "pickle.dump(ephi10, open(\"ephi10_1.p\", 'wb'))\n",
    "\n",
    "pickle.dump(ephi_ratio30, open(\"ephi_ratio30_1.p\", 'wb'))\n",
    "pickle.dump(ephi_wind30, open(\"ephi_wind30_1.p\", 'wb')) \n",
    "pickle.dump(ephi_cenlat30, open(\"ephi_cenlat30_1.p\", 'wb'))\n",
    "pickle.dump(ephi_size30, open(\"ephi_size30_1.p\", 'wb'))\n",
    "pickle.dump(ephi30, open(\"ephi30_1.p\", 'wb'))\n",
    "\n",
    "pickle.dump(ephi_ratio50, open(\"ephi_ratio50_1.p\", 'wb'))\n",
    "pickle.dump(ephi_wind50, open(\"ephi_wind50_1.p\", 'wb')) \n",
    "pickle.dump(ephi_cenlat50, open(\"ephi_cenlat50_1.p\", 'wb'))\n",
    "pickle.dump(ephi_size50, open(\"ephi_size50_1.p\", 'wb'))\n",
    "pickle.dump(ephi50, open(\"ephi50_1.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ephi10.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-bargain",
   "metadata": {},
   "source": [
    "\n",
    "ephi_multi.extend(dec_ephi50)\n",
    "ephi_multi.extend(jan_ephi50)\n",
    "ephi_multi.extend(feb_ephi50)\n",
    "ephi_multi.extend(mar_ephi50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying the regression\n",
    "corr = np.zeros((10,21))\n",
    "pval = np.empty((10,21))\n",
    "pval[:] = np.nan\n",
    "\n",
    "for i in range(0,10):\n",
    "    for j in range(0,21):\n",
    "        reg_temps = tempvals[:,i,j]\n",
    "        rt = []\n",
    "        ep = []\n",
    "        for k in range(0,484):\n",
    "            if k <= 20:\n",
    "                continue\n",
    "            else:\n",
    "                t = k-20\n",
    "                rt.append(reg_temps[k])\n",
    "                ep.append(ephi_multi[t])\n",
    "        #print(len(rt))\n",
    "        #print(len(ep))\n",
    "        test = scipy.stats.pearsonr(rt, ep)\n",
    "        #print(test[0])\n",
    "        corr[i,j] = test[0]\n",
    "        if test[1] <= 0.05:\n",
    "            pval[i,j] = test[1]\n",
    "\n",
    "lats = t2_data['lat'].values\n",
    "lons = t2_data['lon'].values\n",
    "\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "##plot contour of regression\n",
    "fig2, ax2 = plt.subplots()\n",
    "a = ax2.contourf(lons, lats, corr)\n",
    "\n",
    "cbar = fig2.colorbar(a)\n",
    "cbar.ax.set_ylabel('Correlation Coefficient')\n",
    "\n",
    "# use contourf() with proper hatch pattern and alpha value\n",
    "cs = ax2.contourf(lons, lats, pval, hatches=['..'], colors = 'none')\n",
    "\n",
    "plt.xlabel(\"Longitudes $^o$W\")\n",
    "plt.ylabel(\"Latitudes $^o$N\")\n",
    "plt.title(\"Pearsons Correlation\")\n",
    "\n",
    "plt.savefig(\"50hPa_Full2006_PreviousEphi.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-instruction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 June 2020 Environment",
   "language": "python",
   "name": "jun20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
